name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop, pr/* ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  PYTHON_VERSION: "3.11"
  NODE_VERSION: "18"

jobs:
  # Job 1: Code Quality and Security
  code-quality:
    name: Code Quality & Security
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for better analysis
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install flake8 black isort mypy bandit safety
    
    - name: Code formatting check (Black)
      run: |
        black --check --diff .
      continue-on-error: true
    
    - name: Import sorting check (isort)
      run: |
        isort --check-only --diff .
      continue-on-error: true
    
    - name: Linting (flake8)
      run: |
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=88 --statistics
    
    - name: Type checking (mypy)
      run: |
        mypy tradingagents/ extensions/ --ignore-missing-imports
      continue-on-error: true
    
    - name: Security check (bandit)
      run: |
        bandit -r tradingagents/ extensions/ -f json -o bandit-report.json
      continue-on-error: true
    
    - name: Dependency security check (safety)
      run: |
        safety check --json --output safety-report.json
      continue-on-error: true
    
    - name: Upload security reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json
        retention-days: 30

  # Job 2: Unit Tests
  unit-tests:
    name: Unit Tests
    runs-on: ${{ matrix.os }}
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ["3.11", "3.12"]
        
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-xdist pytest-mock
    
    - name: Create test directories
      run: |
        mkdir -p data/logs data/cache data/results
        mkdir -p tests/unit tests/integration
    
    - name: Run unit tests
      env:
        # Mock API keys for testing
        OPENAI_API_KEY: "test-key-mock"
        FINNHUB_API_KEY: "test-key-mock"
        DEEPSEEK_API_KEY: "test-key-mock"
        # Test configuration
        TRADING_ENV: "test"
        DISABLE_ONLINE_TOOLS: "true"
      run: |
        pytest tests/ -v \
          --cov=tradingagents \
          --cov=extensions \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term-missing \
          --junit-xml=test-results.xml \
          -x
    
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.os }}-${{ matrix.python-version }}
        path: |
          test-results.xml
          htmlcov/
          .coverage
        retention-days: 30
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  # Job 3: Integration Tests
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 45
    needs: [unit-tests]
    
    services:
      redis:
        image: redis:alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio docker-compose
    
    - name: Start services
      run: |
        cd deployment/docker
        docker-compose -f docker-compose.test.yml up -d
        sleep 10
    
    - name: Run integration tests
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
        REDIS_URL: "redis://localhost:6379"
        TEST_MODE: "integration"
      run: |
        pytest tests/integration/ -v \
          --junit-xml=integration-results.xml
      continue-on-error: true
    
    - name: Stop services
      if: always()
      run: |
        cd deployment/docker
        docker-compose -f docker-compose.test.yml down
    
    - name: Upload integration test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: integration-test-results
        path: integration-results.xml
        retention-days: 30

  # Job 4: API Tests
  api-tests:
    name: API Tests
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: [unit-tests]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install httpx pytest-asyncio
    
    - name: Start API server
      run: |
        cd extensions/api
        python main.py &
        sleep 10
      env:
        OPENAI_API_KEY: "test-mock-key"
        FINNHUB_API_KEY: "test-mock-key"
        API_TEST_MODE: "true"
    
    - name: Test API endpoints
      run: |
        pytest tests/api/ -v \
          --junit-xml=api-test-results.xml
    
    - name: Upload API test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: api-test-results
        path: api-test-results.xml
        retention-days: 30

  # Job 5: Performance Tests
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [unit-tests]
    if: github.event_name == 'schedule' || contains(github.event.head_commit.message, '[perf]')
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest-benchmark memory-profiler
    
    - name: Run performance tests
      env:
        OPENAI_API_KEY: "test-mock-key"
        FINNHUB_API_KEY: "test-mock-key"
        PERFORMANCE_TEST_MODE: "true"
      run: |
        pytest tests/performance/ -v \
          --benchmark-json=benchmark-results.json \
          --junit-xml=performance-results.xml
    
    - name: Upload performance results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: performance-results
        path: |
          benchmark-results.json
          performance-results.xml
        retention-days: 90

  # Job 6: Docker Build Test
  docker-build:
    name: Docker Build Test
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: [code-quality]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Build Docker image
      run: |
        cd deployment/docker
        docker build -t enhanced-trading:test .
    
    - name: Test Docker image
      run: |
        docker run --rm \
          -e OPENAI_API_KEY="test-mock" \
          -e FINNHUB_API_KEY="test-mock" \
          enhanced-trading:test \
          python -c "import tradingagents; print('Import successful')"
    
    - name: Test Docker Compose
      run: |
        cd deployment/docker
        docker-compose -f docker-compose.test.yml config

  # Job 7: Documentation Build
  docs-build:
    name: Documentation Build
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install documentation dependencies
      run: |
        python -m pip install --upgrade pip
        pip install mkdocs mkdocs-material mkdocs-mermaid2-plugin
    
    - name: Build documentation
      run: |
        mkdocs build --strict
      continue-on-error: true
    
    - name: Upload documentation
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: documentation
        path: site/
        retention-days: 30

  # Job 8: Final Status Check
  ci-status:
    name: CI Status Check
    runs-on: ubuntu-latest
    needs: [code-quality, unit-tests, integration-tests, api-tests, docker-build, docs-build]
    if: always()
    
    steps:
    - name: Check CI Results
      run: |
        echo "Code Quality: ${{ needs.code-quality.result }}"
        echo "Unit Tests: ${{ needs.unit-tests.result }}"
        echo "Integration Tests: ${{ needs.integration-tests.result }}"
        echo "API Tests: ${{ needs.api-tests.result }}"
        echo "Docker Build: ${{ needs.docker-build.result }}"
        echo "Documentation: ${{ needs.docs-build.result }}"
        
        if [ "${{ needs.code-quality.result }}" != "success" ] || \
           [ "${{ needs.unit-tests.result }}" != "success" ] || \
           [ "${{ needs.docker-build.result }}" != "success" ]; then
          echo "❌ Critical jobs failed"
          exit 1
        else
          echo "✅ All critical jobs passed"
        fi
    
    - name: Notify on failure
      if: failure()
      run: |
        echo "CI Pipeline failed. Please check the logs."