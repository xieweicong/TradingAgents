#!/usr/bin/env python3
"""
PostgreSQLæ•°æ®åº“å†™å…¥å™¨ - åŒæ­¥ç‰ˆæœ¬
é¿å…å¼‚æ­¥å¤æ‚æ€§å’Œäº‹ä»¶å¾ªç¯é”™è¯¯
"""

import os
from datetime import datetime
import psycopg2
from psycopg2.extras import RealDictCursor
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DatabaseWriter:
    """åŒæ­¥PostgreSQLæ•°æ®åº“å†™å…¥å™¨"""
    
    def __init__(self, database_url=None):
        self.database_url = database_url or os.getenv('DATABASE_URL')
        self.connection = None
        
    def connect(self):
        """å»ºç«‹åŒæ­¥è¿æ¥"""
        if not self.connection and self.database_url:
            try:
                self.connection = psycopg2.connect(self.database_url)
                logger.info("âœ… PostgreSQL åŒæ­¥è¿æ¥æˆåŠŸ")
            except Exception as e:
                logger.warning(f"âš ï¸ PostgreSQL è¿æ¥å¤±è´¥: {e}")
                self.connection = None
                
    def close(self):
        """å…³é—­è¿æ¥"""
        if self.connection:
            self.connection.close()
            logger.info("ğŸ”’ PostgreSQL è¿æ¥å·²å…³é—­")
    
    def save_analysis_result(self, result):
        """
        åŒæ­¥ä¿å­˜åˆ†æç»“æœåˆ°æ•°æ®åº“
        
        Args:
            result: StockAnalysisResultå¯¹è±¡ï¼ˆæ¥è‡ªanalyzer.pyï¼‰
        """
        # æ¯æ¬¡éƒ½åˆ›å»ºæ–°çš„è¿æ¥ä»¥ä¿è¯çº¿ç¨‹å®‰å…¨
        local_connection = None
        try:
            local_connection = psycopg2.connect(self.database_url)
        except Exception as e:
            logger.warning(f"âš ï¸ PostgreSQL è¿æ¥å¤±è´¥: {e}")
            return
        
        try:
            with local_connection.cursor(cursor_factory=RealDictCursor) as cursor:
                
                # 1. è·å–æ­£ç¡®çš„å…¬å¸åç§°
                company_name = self._get_company_name(result.ticker)
                
                # 1. ç¡®ä¿è‚¡ç¥¨å­˜åœ¨
                cursor.execute(
                    """
                    INSERT INTO stocks (ticker, company_name, created_at, updated_at)
                    VALUES (%s, %s, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
                    ON CONFLICT (ticker) DO UPDATE SET 
                        updated_at = CURRENT_TIMESTAMP,
                        company_name = EXCLUDED.company_name
                    RETURNING id
                    """,
                    (str(result.ticker), str(company_name))
                )
                stock_id = cursor.fetchone()['id']
                
                # 2. ä¿å­˜ä¸»åˆ†æè®°å½• - ä¼˜é›…å¤„ç†é‡å¤key
                cursor.execute(
                    """
                    INSERT INTO analyses (
                        stock_id, task_id, status, analysis_date, started_at, ended_at,
                        processing_time_ms, final_decision, created_at, updated_at
                    ) VALUES (
                        %s, %s, %s, %s, %s, %s, %s, %s, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP
                    ) ON CONFLICT (task_id) DO UPDATE SET
                        updated_at = CURRENT_TIMESTAMP,
                        status = EXCLUDED.status,
                        final_decision = EXCLUDED.final_decision,
                        ended_at = EXCLUDED.ended_at,
                        processing_time_ms = EXCLUDED.processing_time_ms
                    RETURNING id
                    """,
                    (
                        stock_id,
                        str(result.task_id),
                        str(result.status),
                        result.start_time.date() if result.start_time else datetime.now().date(),
                        result.start_time,
                        result.end_time,
                        int(result.total_processing_time * 1000),
                        str(result.final_decision) if result.final_decision else None
                    )
                )
                
                analysis_id = cursor.fetchone()['id']
                
                # 3. ä¿å­˜æ‰€æœ‰agentè¾“å‡º
                self._save_agents(cursor, analysis_id, result)
                
                # æäº¤äº‹åŠ¡
                local_connection.commit()
                logger.info(f"âœ… {result.ticker} æ•°æ®å·²å†™å…¥æ•°æ®åº“ (ID: {analysis_id})")
                
        except psycopg2.errors.UniqueViolation as e:
            local_connection.rollback()
            logger.warning(f"âš ï¸ é‡å¤ä»»åŠ¡ID: {result.task_id} - å·²æ›´æ–°ç°æœ‰è®°å½•")
        except Exception as e:
            local_connection.rollback()
            logger.error(f"âŒ æ•°æ®åº“å†™å…¥å¤±è´¥: {result.ticker} - {str(e)}")
            logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        finally:
            # ç¡®ä¿çº¿ç¨‹å®‰å…¨çš„æœ¬åœ°è¿æ¥è¢«å…³é—­
            try:
                local_connection.close()
            except Exception as e:
                logger.warning(f"å…³é—­è¿æ¥æ—¶å‡ºé”™: {e}")
    
    def _save_agents(self, cursor, analysis_id, result):
        """åŒæ­¥ä¿å­˜agentæ•°æ®"""
        
        agents_data = []
        
        # åˆ†æå¸ˆè¾“å‡º
        for agent_type, output in getattr(result, 'analyst_outputs', {}).items():
            if output and output.content:
                role = self._get_role(agent_type)
                agents_data.append((output.agent_name, agent_type, role, output.content))
        
        # ç ”ç©¶è¾“å‡º
        for agent_type, output in getattr(result, 'research_outputs', {}).items():
            if output and output.content:
                role = self._get_role(agent_type)
                agents_data.append((output.agent_name, agent_type, role, output.content))
        
        # é£é™©è¾“å‡º
        for agent_type, output in getattr(result, 'risk_outputs', {}).items():
            if output and output.content:
                role = self._get_role(agent_type)
                agents_data.append((output.agent_name, agent_type, role, output.content))
        
        # äº¤æ˜“å†³ç­–
        if result.trader_output and result.trader_output.content:
            agents_data.append((
                result.trader_output.agent_name,
                'trader', 'decision',
                result.trader_output.content
            ))
        
        # ç»„åˆå†³ç­–
        if result.portfolio_output and result.portfolio_output.content:
            agents_data.append((
                result.portfolio_output.agent_name,
                'portfolio_manager', 'decision',
                result.portfolio_output.content
            ))
        
        # æ‰¹é‡æ’å…¥æ‰€æœ‰agent
        for agent_name, agent_type, role, content in agents_data:
            cursor.execute(
                """
                INSERT INTO agent_outputs (
                    analysis_id, agent_name, agent_type, role, content, created_at, updated_at
                ) VALUES (%s, %s, %s, %s, %s, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
                """,
                (analysis_id, agent_name, agent_type, role, str(content))
            )
    
    def _get_company_name(self, ticker):
        """ä»Yahoo Financeè·å–æ­£ç¡®çš„å…¬å¸åç§°"""
        try:
            import yfinance as yf
            stock = yf.Ticker(ticker)
            info = stock.info
            
            # å°è¯•å¤šä¸ªå­—æ®µè·å–æœ€å‡†ç¡®çš„å…¬å¸åç§°
            company_name = info.get('longName') or info.get('shortName') or info.get('displayName') or ticker
            return str(company_name)
        except Exception as e:
            logger.warning(f"æ— æ³•è·å–{ticker}çš„å…¬å¸åç§°: {e}")
            return ticker  # å¤±è´¥æ—¶ä½¿ç”¨è‚¡ç¥¨ä»£ç 
    
    def _get_role(self, agent_type):
        """æ ¹æ®agentç±»å‹è¿”å›è§’è‰²"""
        role_map = {
            'market_analyst': 'analytical',
            'fundamentals_analyst': 'analytical', 
            'news_analyst': 'analytical',
            'sentiment_analyst': 'analytical',
            'bull_researcher': 'research',
            'bear_researcher': 'research',
            'research_manager': 'research',
            'risky_analyst': 'risk_management',
            'safe_analyst': 'risk_management',
            'neutral_analyst': 'risk_management',
            'trader': 'decision',
            'portfolio_manager': 'decision'
        }
        return role_map.get(agent_type, 'analytical')
    
    def test_connection(self):
        """æµ‹è¯•å½“å‰æ•°æ®åº“è¿æ¥"""
        if not self.database_url:
            logger.error("âŒ æœªè®¾ç½®DATABASE_URLç¯å¢ƒå˜é‡")
            return False
            
        try:
            self.connect()
            if self.connection:
                with self.connection.cursor() as cursor:
                    cursor.execute("SELECT version()")
                    version = cursor.fetchone()[0]
                    logger.info(f"âœ… PostgreSQLç‰ˆæœ¬: {version.split()[1]}")
                return True
            return False
        except Exception as e:
            logger.error(f"âŒ è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False
        finally:
            try:
                self.close()
            except:
                pass  # Ensure we always return False instead of crashing
    
    def has_analysis_for_today(self, ticker, analysis_date=None):
        """æ£€æŸ¥ä»Šå¤©æ˜¯å¦å·²ç»åˆ†æè¿‡è¯¥è‚¡ç¥¨"""
        conn = None
        try:
            conn = psycopg2.connect(self.database_url)
            
            if analysis_date is None:
                analysis_date = datetime.now().date()
            else:
                from datetime import datetime
                analysis_date = datetime.strptime(analysis_date, "%Y-%m-%d").date()
                
            with conn.cursor() as cursor:
                cursor.execute(
                    """
                    SELECT 1
                    FROM analyses a
                    JOIN stocks s ON a.stock_id = s.id
                    WHERE s.ticker = %s 
                      AND a.analysis_date = %s
                      AND a.status = 'completed'
                    LIMIT 1
                    """,
                    (str(ticker), analysis_date)
                )
                return cursor.fetchone() is not None
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥é‡å¤åˆ†æå¤±è´¥: {e}")
            return False
        finally:
            if conn:
                try:
                    conn.close()
                except:
                    pass
    
    def get_recent_analyses(self, limit=5):
        """è·å–æœ€è¿‘åˆ†æç”¨äºéªŒè¯"""
        conn = None
        try:
            conn = psycopg2.connect(self.database_url)
            with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                cursor.execute(
                    """
                    SELECT s.ticker, s.company_name, a.final_decision, a.analysis_date,
                           a.processing_time_ms/1000.0 as seconds, a.created_at, COUNT(ao.id) as agents
                    FROM analyses a 
                    JOIN stocks s ON a.stock_id = s.id 
                    LEFT JOIN agent_outputs ao ON a.id = ao.analysis_id
                    GROUP BY a.id, s.ticker, s.company_name
                    ORDER BY a.created_at DESC 
                    LIMIT %s
                    """,
                    (limit,)
                )
                return cursor.fetchall()
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
            return []
        finally:
            if conn:
                try:
                    conn.close()
                except:
                    pass


class DatabaseManager:
    """æ•°æ®åº“ç®¡ç†å™¨ - ä¸ç°æœ‰åˆ†æå™¨é›¶è€¦åˆ"""
    
    def __init__(self, database_url=None):
        self.writer = DatabaseWriter(database_url)
        
    def save_results(self, result):
        """åŒæ­¥ä¿å­˜ç»“æœ - æ¯çº¿ç¨‹ç‹¬ç«‹è¿æ¥"""
        logger.info("ğŸ“ æ­£åœ¨å†™å…¥åˆ°PostgreSQL...")
        # ç›´æ¥ä¿å­˜ï¼Œä¸æµ‹è¯•è¿æ¥ï¼Œä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„æ–¹æ³•
        try:
            self.writer.save_analysis_result(result)
            logger.info("âœ… PostgreSQLæ•°æ®ä¿å­˜å®Œæˆ")
        except Exception as e:
            logger.warning(f"âš ï¸ PostgreSQLä¿å­˜å¤±è´¥: {e}ï¼Œä½¿ç”¨æœ¬åœ°æ–‡ä»¶å­˜å‚¨")
    
    def close_connection(self):
        """ç¨‹åºç»“æŸæ—¶è°ƒç”¨"""
        self.writer.close()